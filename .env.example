# 이 파일을 .env로 바꾸고 변수들을 환경에 맞게 수정하세요
# Rename this file to .env and modify the variables to suit your environment.

# InfluxDB Settings
INFLUX_USERNAME=username
INFLUX_PASSWORD=password
INFLUX_ORG=your_organization
INFLUX_DATABASE=your-datebase-name
INFLUX_ADMIN_TOKEN=replace-it-with-a-complicated-random-string

#CORS_ALLOW_ORIGIN
CORS_ALLOW_ORIGIN=*

INFLUX_URL=http://localhost:8181

LLM_PROVIDER=ollama
# Use Docker service name so apilog-api can reach Ollama container
LLM_ENDPOINT=http://ollama:11434
# Trimmed model tag (no trailing spaces)
LLM_MODEL=llama3:8b
LLM_TEMPERATURE=0.2
LLM_TIMEOUT_S=60
# Disable insights cache while testing (0=off)
AI_INSIGHTS_EXPLAIN_CACHE_TTL=0