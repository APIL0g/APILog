############################################################
# Docker Compose for APILog Production Environment
# APILog 실제 배포 환경용 Docker Compose
############################################################

services:
  ############################################################
  # 1) InfluxDB 3 Core
  #    Time-series DB (HTTP API on port 8181, localhost only)
  #    시계열 데이터베이스 (로컬호스트에서만 8181 포트 제공)
  ############################################################
  influxdb3-core:
    image: influxdb:3-core
    container_name: influxdb3-core

    environment:
      # Storage type: local filesystem
      # 스토리지 타입: 로컬 파일 시스템
      INFLUXDB3_OBJECT_STORE: file

      # Data directory (persisted to volume)
      # 데이터 디렉터리 (볼륨에 영구 저장)
      INFLUXDB3_DB_DIR: /var/lib/influxdb3

      # Node ID (required argument)
      # 노드 ID (필수 인자)
      INFLUXDB3_NODE_ID: influx-node0

      INFLUXDB3_START_WITHOUT_AUTH: "true"

    command:
      - influxdb3
      - serve
      - --log-filter
      - info
      - --object-store
      - file
      - --plugin-dir
      - /plugins
      - --node-id
      - influx-node0

    volumes:
      # Database / catalog / parquet storage
      # 데이터베이스, 카탈로그, 파케 저장 볼륨
      - influx-data:/var/lib/influxdb3

      # Home metadata for influxdb3 user
      # influxdb3 유저 홈 메타데이터
      - influx-meta:/home/influxdb3/.influxdb3

      # Plugins directory (rollups, custom scripts)
      # 플러그인 저장소 (롤업, 커스텀 스크립트)
      - influx-plugins:/plugins

    restart: unless-stopped


  ############################################################
  # 2) apilog-api (FastAPI backend)
  #    Event ingestion & query API for APILog
  #    APILog의 이벤트 수집 및 조회용 백엔드 API
  ############################################################
  apilog-api:
    container_name: apilog-api
    build: ./back/app

    environment:
      INFLUX_URL: http://influxdb3-core:8181
      INFLUX_TOKEN: ${INFLUX_TOKEN}       # prod에서는 실제 토큰을 .env에
      INFLUX_ORG: ${INFLUX_ORG}
      INFLUX_BUCKET: ${INFLUX_DATABASE}
      CORS_ALLOW_ORIGIN: ${CORS_ALLOW_ORIGIN}
      LLM_PROVIDER: ${LLM_PROVIDER}
      LLM_ENDPOINT: ${LLM_ENDPOINT}
      LLM_MODEL: ${LLM_MODEL}
      LLM_TEMPERATURE: ${LLM_TEMPERATURE}
      LLM_TIMEOUT_S: ${LLM_TIMEOUT_S}

    depends_on:
      - influxdb3-core
      - ollama

    expose:
      - "8000"  # 내부 컨테이너에서만 접근

    volumes:
      - snapshots:/snapshots

    restart: unless-stopped


  ############################################################
  # 3) apilog-nginx (Frontend + Reverse Proxy)
  #    프론트엔드 정적파일 서빙 및 API 프록시
  ############################################################
  apilog-nginx:
    container_name: apilog-nginx
    build:
      context: .
      dockerfile: infra/nginx/Dockerfile

    ports:
      - "8080:80"   # 예: Cloudflare / 외부 Nginx → :8080

    depends_on:
      - apilog-api

    restart: unless-stopped


  ############################################################
  # 4) ollama (Local LLM Server)
  #    AI 모델 로컬 인퍼런스 서버 (포트 11434)
  ############################################################
  ollama:
    image: ollama/ollama:latest
    container_name: ollama

    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=1h

    gpus: all

    volumes:
      - ollama-data:/root/.ollama

    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 5s
      retries: 20

    restart: unless-stopped

    # GPU 환경이면 아래 주석 해제해서 GPU 사용 가능
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - capabilities: ["gpu"]


##############################################################
# Named Volumes (Persistent storage)
# 영구 데이터 저장소
##############################################################
volumes:
  influx-data:
  influx-meta:
  influx-plugins:
  snapshots:
  ollama-data:
